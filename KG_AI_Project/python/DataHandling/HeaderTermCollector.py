import os
import csv
import pandas as pd
from typing import Set

class HeaderTermCollector:
    def __init__(self, csv_dir: str, encoding: str = "utf-8-sig"):
        self.csv_dir = csv_dir
        self.encoding = encoding
        self.all_columns: Set[str] = set()
        self.all_terms: Set[str] = set()

    def collect(self):
        for filename in os.listdir(self.csv_dir):
            if filename.endswith(".csv"):
                path = os.path.join(self.csv_dir, filename)
                try:
                    df = pd.read_csv(path, nrows=0, encoding=self.encoding)
                    self.all_columns.update(df.columns)
                except Exception as e:
                    print(f"âš ï¸ [{filename}] â†’ ì»¬ëŸ¼ ë¡œë”© ì‹¤íŒ¨: {e}")

    def tokenize(self, delimiter: str = "_"):
        for col in self.all_columns:
            tokens = col.split(delimiter)
            for t in tokens:
                if t.strip():
                    self.all_terms.add(t.strip())

    def run(self, print_summary=True):
        self.collect()
        self.tokenize()
        if print_summary:
            print(f"âœ… ì´ {len(self.all_columns)}ê°œ ì»¬ëŸ¼ëª… ìˆ˜ì§‘")
            print(f"ğŸ§© ì´ {len(self.all_terms)}ê°œ ìœ ë‹ˆí¬ í† í° ë‹¨ì–´ ìˆ˜ì§‘\n")
            # for term in sorted(self.all_terms):
            #     print(f" - {term}")

    def save_terms(self, path):
        with open(path, "w", encoding="utf-8-sig", newline="") as f:
            writer = csv.writer(f)
            writer.writerow(["í•œê¸€í—¤ë”"])  # ì²« ë²ˆì§¸ ì—´ ì´ë¦„
            for term in sorted(self.all_terms):
                writer.writerow([term])
        print(f"ğŸ“‚ ì €ì¥ê²½ë¡œ : {path}")
        print(f"ğŸ’¾ í—¤ë” ë‹¨ì–´ ëª©ë¡ CSV ì €ì¥ ì™„ë£Œ")